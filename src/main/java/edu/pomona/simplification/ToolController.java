package edu.pomona.simplification;

import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Properties;
import java.util.UUID;

import javax.servlet.http.HttpServletRequest;

import org.springframework.context.annotation.Scope;
//import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.SessionAttributes;

import edu.pomona.simplification.lexicalChainsAnnotator.LexicalChainCall;
import edu.pomona.simplification.lexicalChainsAnnotator.LexicalChainType;
import edu.pomona.simplification.sentence.DoubleNegationChecker;
import edu.pomona.simplification.sentence.GrammarChangeSuggester;
import edu.pomona.simplification.sentence.GrammarRule;
import edu.pomona.simplification.substitution.AffixSubstitutionGenerator;
import edu.pomona.simplification.substitution.DuplicateStemFilter;
import edu.pomona.simplification.substitution.MorphNegation;
import edu.pomona.simplification.substitution.POSOnlyInputFilter;
import edu.pomona.simplification.substitution.SimplificationOption;
import edu.pomona.simplification.substitution.SubstitutionDriver;
import edu.pomona.simplification.substitution.WordFrequencyFilter;
import edu.pomona.simplification.substitution.WordFrequencyInputFilter;
import edu.pomona.simplification.substitution.WordnetSynonymGenerator;
import edu.pomona.simplification.text.Nominals;
import edu.pomona.simplification.text.POSTaggedWord;
import edu.pomona.simplification.text.PartOfSpeech;
import edu.pomona.simplification.text.TextProcessor;
import edu.pomona.simplification.text.UMLS;
import edu.pomona.simplification.text.Wordnet;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.CoreDocument;
import edu.stanford.nlp.pipeline.CoreSentence;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.trees.Tree;
import edu.pomona.simplification.text.PorterStemmer;
//import edu.stanford.nlp.semgraph.SemanticGraph;
//import edu.stanford.nlp.trees.Tree;
//import edu.pomona.simplification.text.SentenceRuleGenerator;
import edu.pomona.simplification.text.TextFrequencyCalculator;
//import edu.pomona.simplification.User;
//import edu.pomona.simplification.UserRepository;

// TODO:
// - Change the substitution drivers to return a "Substition" class object, rather than a string.  Use
//   this object to encode the source information, rather than as an appended string.  Then, either
//   try and update the simplification option or, right before returning, turn the Substition object
//   into a normal string.


@Controller
@Scope("session")
@SessionAttributes("session-id")
public class ToolController {
	
	//@Autowired // This means to get the bean called userRepository
    // Which is auto-generated by Spring, we will use it to handle the data
	//private UserRepository userRepository;
	
	private PorterStemmer stemmer = new PorterStemmer();

	//private TextProcessor textProcessor = new TextProcessor();	
	
	private StanfordCoreNLP pipeline;

	private WordFrequencyInputFilter frequencyFilter = new WordFrequencyInputFilter();
	
	private SubstitutionDriver synonymDriver = new SubstitutionDriver();
	private SubstitutionDriver nominalDriver = new SubstitutionDriver();
	private SubstitutionDriver negationDriver = new SubstitutionDriver();
	private SubstitutionDriver affixDriver = new SubstitutionDriver();

	private WordnetSynonymGenerator wordnetSynonymGenerator;
	private UMLS UMLSGenerator;
	private Nominals nominalGenerator;

	private GrammarChangeSuggester grammarChangeSuggester = new GrammarChangeSuggester();
	
	private DoubleNegationChecker doubleNegationChecker;
	
	private String id;
	
	private int textId;
	
	
//	private SentenceRuleGenerator sentenceRuleGenerator = new SentenceRuleGenerator();
	
	public ToolController() {
		Wordnet wn = new Wordnet();

		//////////////////////////////
		// setup the synonymDriver
		// setup prefilter for frequency
		synonymDriver.addInputFilter(frequencyFilter);

		// setup the synonym sources
		wordnetSynonymGenerator = new WordnetSynonymGenerator(wn);
		UMLSGenerator = new UMLS();
		nominalGenerator = new Nominals();

		// setup postfilters for improved frequency and to avoid duplicates
		synonymDriver.addResultFilter(new WordFrequencyFilter());
		synonymDriver.addResultFilter(new DuplicateStemFilter());
		
		//////////////////////////////
		// setup the morph negation driver
		MorphNegation morphNegation = new MorphNegation(stemmer);
		negationDriver.addGenerator(morphNegation);

		//////////////////////////////
		// setup the affix driver
		affixDriver.addInputFilter(frequencyFilter);
		affixDriver.addGenerator(new AffixSubstitutionGenerator(wn));

		//////////////////////////////
		// setup double negation checker
		doubleNegationChecker = new DoubleNegationChecker(morphNegation);
		
		//////////////////////////////
		// setup the nominal checker
		nominalDriver.addInputFilter(new POSOnlyInputFilter(PartOfSpeech.NOUN));
		nominalDriver.addInputFilter(frequencyFilter);
		nominalDriver.addGenerator(nominalGenerator);
		
		/////////////////////////////
		// setup NLP pipeline
		Properties props = new Properties();
	    props.setProperty("annotators", "tokenize,ssplit,parse,depparse");
	    props.setProperty("threads", Integer.toString(Preferences.NUM_PARSER_THREADS));
	    pipeline = new StanfordCoreNLP(props);
	    
	    
	    id = UUID.randomUUID().toString();
	    textId = 0;
	    
	}

	@PostMapping("/statistics")
	@ResponseBody
	public Stats getStatistics(@RequestParam("value") String text) {
		// parse, etc. the text
	    Annotation annotator = new Annotation(text);
	    pipeline.annotate(annotator);	    
	    CoreDocument document = new CoreDocument(annotator);
		
		ArrayList<POSTaggedWord> words = TextProcessor.getCountableWords(document);
		double sum = 0.0;
		int nouns = 0;
		int verbs = 0;

		for(long f: TextFrequencyCalculator.taggedWordFreqLookup(words)) {
			sum += f;
		}
		
		for( CoreSentence sentence: document.sentences() ){
			Tree parseTree = sentence.constituencyParse();
			for( CoreLabel leaf: parseTree.taggedLabeledYield() ) {
				String pos = leaf.value();
				if( pos.startsWith("NN") ) {
					nouns++;
				}else if( pos.startsWith("VB") ){
					verbs++;
				}/*else if( pos.startsWith("JJ") ) {
			adjectives++;
			}else if( pos.startsWith("PRP") ) {
			pronouns++;
			}else if( pos.equals("IN") ) {
			prepositions++;
			}*/
			}
		}

		return new Stats(words.size(), sum / words.size(), nouns, verbs);
	}
	
	@PostMapping("/exactLexicalChains")
	@ResponseBody
	public String getExactLexical(@RequestParam("value") String text){
		System.out.println("Getting into the function getExactLexical" );
		LexicalChainCall caller = new LexicalChainCall();
		return caller.processTextToChains(LexicalChainType.Exact, text);
	}
	
	@PostMapping("/synonymousLexicalChains")
	@ResponseBody
	public String getSynonymousLexical(@RequestParam("value") String text){
		System.out.println("Getting into the function synonymousLexicalChains" );
		LexicalChainCall caller = new LexicalChainCall();
		return caller.processTextToChains(LexicalChainType.Synonymous, text);
	}
	
	@PostMapping("/semanticLexicalChains")
	@ResponseBody
	public String getSemanticLexical(@RequestParam("value") String text){
		System.out.println("Getting into the function semanticLexicalChains" );
		LexicalChainCall caller = new LexicalChainCall();
		return caller.processTextToChains(LexicalChainType.Semantic, text);
	}
	

	@PostMapping("/simplify")
	@ResponseBody
	public List<SimplificationResult> getSimplifications(@RequestParam("value") String text,
			@RequestParam("wordnetChecked") boolean wordnetChecked,
			@RequestParam("UMLSChecked") boolean UMLSChecked,
			@RequestParam("negationChecked") boolean negationChecked,
			@RequestParam("affixChecked") boolean affixChecked,
			@RequestParam("nominalChecked") boolean nominalChecked,
			@RequestParam("sliderValue") int freqSliderValue) {	
		
		 System.out.println("Getting into the function getSimplifications" );
		
		// set the frequency threshold
		if( freqSliderValue >= 0 && freqSliderValue < Preferences.FREQUENCY_THRESHOLDS.length ) {
			frequencyFilter.setFrequencyThreshold(Preferences.FREQUENCY_THRESHOLDS[freqSliderValue]);
		}
		
	    // parse, etc. the text
	    Annotation annotator = new Annotation(text);
	    pipeline.annotate(annotator);	    
	    CoreDocument document = new CoreDocument(annotator);
	    
	   
	    
		// get the sentences in the text
		//List<Tree> sentences = TextProcessor.getParsedSentences(document);

		// -------- WORD-LEVEL PROCESSING ---------
		// get all of the words that could be simplified
		ArrayList<POSTaggedWord> words = TextProcessor.dedup(TextProcessor.getCountableWords(document));
		// add count information here so that any substitution driver will have access
		TextFrequencyCalculator.addFrequencyInformation(words);

		// setup the requested synonyms
		synonymDriver.clearGenerators();

		if( wordnetChecked ) {
			synonymDriver.addGenerator(wordnetSynonymGenerator);
		}
		
		if( UMLSChecked ) {
			synonymDriver.addGenerator(UMLSGenerator);
		}

		List<SimplificationOption> syns = synonymDriver.getAllSynonyms(words);
		List<SimplificationOption> negationSubs;
		
		// handle negation optionally
		if( negationChecked ) {
			negationSubs = negationDriver.getAllSynonyms(words);
		}else {
			negationSubs = new ArrayList<SimplificationOption>(0);
		}

		// handle affixes optionally
		List<SimplificationOption> affixSubs;

		if( affixChecked ) {
			affixSubs = affixDriver.getAllSynonyms(words);
		}else {
			affixSubs = new ArrayList<SimplificationOption>(0); 
		}
		
		// handle nominals optionally
		List<SimplificationOption> nominalSubs;
		
		if( nominalChecked ) {
			nominalSubs = nominalDriver.getAllSynonyms(words);
		}else {
			nominalSubs = new ArrayList<SimplificationOption>(0);
		}

		// put the "good" types of synonym replacers together
		List<List<SimplificationOption>> allSubs = new ArrayList<List<SimplificationOption>>(3);
		allSubs.add(syns);
		allSubs.add(negationSubs);
		allSubs.add(nominalSubs);
		
		// merge all the word simplifications, with priority to those in allSubs
		List<SimplificationOption> merged = mergeOptions(allSubs, affixSubs);		
		List<SimplificationResult> finalSet = new ArrayList<SimplificationResult>(merged.size());

		// create the final output objects to send back to the frontend for the word substitutions
		for( SimplificationOption s: merged ) {
			finalSet.add(new SimplificationResult(s));
		}

		// -------- SENTENCE-LEVEL PROCESSING ---------
		for( CoreSentence sentence: document.sentences() ) {
			// check double negation
			if( doubleNegationChecker.hasDoubleNegation(sentence) ) {
				finalSet.add(generateSimplificationResult(sentence.text(), sentence.text(), doubleNegationChecker.getChangeInformation()));	
			}else {
				// grammar checking
				checkSentenceForGrammarRuleApplication(sentence, finalSet);
			}
		}
		
		return finalSet;
	}
	
	/*
	 *  Table 1) SessionID, text id, text, stats data, which button was clicked, stats data, checkboxes
	 *  table 2) SessionID, textid, original word, replaced word, options available
	 * */
	@PostMapping("/analytics")
	@ResponseBody
	public SessionInformation getAnalytics(
			@RequestParam("value") String text,
			@RequestParam("wordnetChecked") boolean wordnetChecked,
			@RequestParam("UMLSChecked") boolean UMLSChecked,
			@RequestParam("negationChecked") boolean negationChecked,
			@RequestParam("affixChecked") boolean affixChecked,
			@RequestParam("nominalChecked") boolean nominalChecked,
			@RequestParam("originalWC") String originalWC,
			@RequestParam("originalWF") String originalWF,
			@RequestParam("revisedWC") String revisedWC,
			@RequestParam("revisedWF") String revisedWF,
			@RequestParam("buttonClicked") String buttonClicked,
			HttpServletRequest request
			) {
		
		//HttpSession session = request.getSession();
		java.sql.Connection conn = null;
	    java.sql.Statement stmt = null;
	    
	    //String uname=(String)request.getSession().getAttribute("id");
	    
	    if(id == null) {
	    	id = UUID.randomUUID().toString();
	    }
	    if(buttonClicked.equals("Simplify")) {
	    	textId++;
	    }
	    
	    int owc = Integer.parseInt(originalWC);
	    int owf = Integer.parseInt(originalWF);
	    int rwc = Integer.parseInt(revisedWC);
	    int rwf = Integer.parseInt(revisedWF);
	    
	    try {
			Class.forName("com.mysql.jdbc.Driver");
			
			conn = DriverManager.getConnection(Preferences.ANALYTICS_DATABASE_URL, Preferences.USER, Preferences.PASSWORD);
			
			stmt = conn.createStatement();
			
			String sql = "INSERT INTO simplifytext ( session_id, system_version, text_id, text_string, button_clicked, wordnet_checked,"
					+ " UMLS_checked, negation_checked, affix_checked, nominal_checked, original_wc, original_wf, revised_wc, revised_wf)" +
			        "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
			
			PreparedStatement preparedStatement = conn.prepareStatement(sql);
			preparedStatement.setString(1, id);
			preparedStatement.setString(2, Preferences.SYSTEM_VERSION);
			preparedStatement.setInt(3, textId);
			preparedStatement.setString(4, text);
			preparedStatement.setString(5, buttonClicked);
			preparedStatement.setBoolean(6, wordnetChecked);
			preparedStatement.setBoolean(7, UMLSChecked);
			preparedStatement.setBoolean(8, negationChecked);
			preparedStatement.setBoolean(9, affixChecked);
			preparedStatement.setBoolean(10, nominalChecked);
			preparedStatement.setInt(11, owc);
			preparedStatement.setInt(12, owf);
			preparedStatement.setInt(13, rwc);
			preparedStatement.setInt(14, rwf);
			preparedStatement.executeUpdate(); 
		} catch (ClassNotFoundException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (SQLException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	    
		return new SessionInformation(id, textId);
	    // parse, etc. the text
	    
	}
	
	@PostMapping("/replacetext")
	@ResponseBody
	public int getReplaceText(
			@RequestParam("originalWord") String originalWord,
			@RequestParam("replacedWord") String replacedWord,
			@RequestParam("sourceOfWord") String sourceOfWord,
			@RequestParam("optionsOfWord") String optionsOfWord,
			HttpServletRequest request
			) {
		
		//HttpSession session = request.getSession();
		java.sql.Connection conn = null;
	    java.sql.Statement stmt = null;
	    
	    try {
			Class.forName("com.mysql.jdbc.Driver");
			
			conn = DriverManager.getConnection(Preferences.ANALYTICS_DATABASE_URL, Preferences.USER, Preferences.PASSWORD);
			
			stmt = conn.createStatement();
			
			String sql = "INSERT INTO replacedtext ( session_id, text_id, original_word, replaced_word, source_of_word, options_of_word)" +
			        "VALUES (?, ?, ?, ?, ?, ?)";
			
			PreparedStatement preparedStatement = conn.prepareStatement(sql);
			preparedStatement.setString(1, id);
			preparedStatement.setInt(2, textId);
			preparedStatement.setString(3, originalWord);
			preparedStatement.setString(4, replacedWord);
			preparedStatement.setString(5, sourceOfWord);
			preparedStatement.setString(6, optionsOfWord);
			preparedStatement.executeUpdate(); 
			
		} catch (ClassNotFoundException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (SQLException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

		
		return 1;
	    // parse, etc. the text
	    
	}

	private void checkSentenceForGrammarRuleApplication(CoreSentence sentence, List<SimplificationResult> finalSet) {
		Tree parseTree = sentence.constituencyParse();
		List<GrammarRule> foundRules = grammarChangeSuggester.checkSentence(parseTree);
		ArrayList<POSTaggedWord> sentenceWords = TextProcessor.getSentenceCountableWords(sentence);

		if( foundRules.size() > 0 ){
			// for now, just grab the first rule and create a new SimplificationResult for it
			GrammarRule rule = foundRules.get(0);
			//finalSet.add(grammarChangeSuggester.generateSimplificationResult(sentence, changeInformation));
			String coveredText = rule.getTregexMatch(parseTree);
			String sentenceText = sentence.text();
			
			System.out.println("Sentence: " + sentenceText);
			System.out.println("Covered: " + coveredText);

			if(sentenceWords.size() > 25){
				finalSet.add(generateSimplificationResult(sentenceText, sentenceText, rule.getSentenceLengthExceededInfo()));
			}else if( !coveredText.equals("") && sentenceText.contains(coveredText)){
				finalSet.add(generateSimplificationResult(sentenceText, coveredText, rule.getChangeInformation()));
				//finalSet.add(generateSimplificationResult(sentence.text(), rule.getChangeInformation()));
			}else{
				finalSet.add(generateSimplificationResult(sentenceText, sentenceText, rule.getChangeInformation()));
			}
		}
	}
	
	private SimplificationResult generateSimplificationResult(String sentenceText, String coveredText, String changeInformation) {
		//String sentenceText = sentence.text();
		// if it's too short, just return the whole sentence as the start, minus the last character.
		if( sentenceText.length() < (Preferences.BEGIN_CHARACTERS_TO_RETURN_FOR_SENTENCE ) ) {
			System.out.println("first part: " + sentenceText.substring(0, sentenceText.length()-1));
			
			return new SimplificationResult(sentenceText.substring(0, sentenceText.length()-1),
					 					   coveredText,
					 					   changeInformation);
		}else {
			System.out.println("Long enough");
			return new SimplificationResult(sentenceText.substring(0, Preferences.BEGIN_CHARACTERS_TO_RETURN_FOR_SENTENCE),
					   coveredText,
					   changeInformation);
		}
	}

	/**
	 * Combine all of the options in substitutions into a single list of subsitutions.  Add in backupSubstitutions *only if*
	 * one doesn't exists in the substitutions
	 * 
	 * 
	 * @param substitutions
	 * @param backupSubstitutions
	 * @return
	 */
	public static List<SimplificationOption> mergeOptions(List<List<SimplificationOption>> substitutions, List<SimplificationOption> backupSubstitutions){
		List<SimplificationOption> combined = new ArrayList<SimplificationOption>();
		HashMap<String, SimplificationOption> wordToSubs = new HashMap<String, SimplificationOption>();

		for( List<SimplificationOption> sub: substitutions ) {
			for(SimplificationOption option: sub ) {
				String word = option.getWord();
				
				if( wordToSubs.containsKey(word)) {
					// add these to the end of the existing list
					wordToSubs.get(word).getSimplifications().addAll(option.getSimplifications());
				}else {
					// add this word to the final set of options AND add it into the hashmap
					SimplificationOption temp = new SimplificationOption(option);
					combined.add(temp);
					wordToSubs.put(word, temp);
				}
			}
		}

		// do a final check for backup substitutions
		for(SimplificationOption option: backupSubstitutions ) {
			String word = option.getWord();

			// add it if we didn't see any substitutions from the other options
			if( !wordToSubs.containsKey(word) ) {
				SimplificationOption temp = new SimplificationOption(option);
				combined.add(temp);
				wordToSubs.put(word, temp);
			}
		}

		return combined;
	}
}
